{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10, train_ds, val_ds\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_ds = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise, Pointwise convolution - mobilenet을 구현하기 위한 depthwise seperable convolution\n",
    "class depth_point(nn.Module):\n",
    "    def __init__(self, input_size, output_size, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        #groups = input_size로 depthwise convolution을 진행\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(input_size, input_size, 3, stride=stride, padding=1, groups=input_size),\n",
    "            nn.BatchNorm2d(input_size),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "        # kernel size를 1로 하여 pointwise convolution을 진행\n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(input_size, output_size, 1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(output_size),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shufflenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel shuffle and group convolution ---------------------------------\n",
    "# 처음 group convolution 후 channel shuffle을 위한 함수\n",
    "def channel_shuffle(x, groups):\n",
    "    batch_size, num_channels, height, width = x.size()\n",
    "    assert (num_channels % groups == 0), ('num_channels should be '\n",
    "                                          'divisible by groups')\n",
    "    channels_per_group = num_channels // groups\n",
    "\n",
    "    x = x.view(batch_size, groups, channels_per_group, height, width)\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "    x = x.view(batch_size, -1, height, width)\n",
    "    return x\n",
    "\n",
    "# group convolution layer - group=8로 설정하였고 batchnorm, relu\n",
    "class g_conv(nn.Module):\n",
    "    def __init__(self, input_size, output_size, stride=1):\n",
    "        super().__init__() \n",
    "\n",
    "        self.gconv = nn.Sequential(\n",
    "            nn.Conv2d(input_size, output_size, 3, stride=stride, padding=1, groups=8),\n",
    "            nn.BatchNorm2d(output_size),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.gconv(x)\n",
    "        return x\n",
    "#-----------------------------------------------------------------------\n",
    "# MobileNetV1_shuffleNet\n",
    "class MobileNetv4(nn.Module):\n",
    "    def __init__(self, group=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.group = group\n",
    "        self.init = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # dw, pw를 g_conv 하나로 변경\n",
    "        self.conv4 = g_conv(32, 512, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "        )\n",
    "        # dw, pw를 g_conv 하나로 변경\n",
    "        self.conv6 = nn.Sequential(\n",
    "            g_conv(512, 1024, stride=2)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init(x)\n",
    "        x = self.conv4(x)\n",
    "        # g_conv 후 channel shuffle\n",
    "        x = channel_shuffle(x, self.group)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise, Pointwise convolution + dilation \n",
    "class depth_point2(nn.Module):\n",
    "    def __init__(self, input_size, output_size, padding ,stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(input_size, input_size, 3, stride=stride, padding=padding, dilation=2, groups=input_size),\n",
    "            nn.BatchNorm2d(input_size),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "\n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(input_size, output_size, 1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(output_size),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "# MobileNetV1\n",
    "class MobileNetv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.init = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1, dilation=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv1 = depth_point(32, 64)\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            depth_point(64, 128 , stride=2),\n",
    "            depth_point(128, 128)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            depth_point(128, 256, stride=2),\n",
    "            depth_point(256, 256)\n",
    "        )\n",
    "        \n",
    "        self.conv4 = depth_point(256, 512, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            depth_point(512, 1024, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            depth_point(1024, 1024, stride=2)\n",
    "        )\n",
    "\n",
    "        self.convd1 = nn.Conv2d(3, 32, 1, stride=1, padding=0, dilation=1)      ## channel\n",
    "        self.pool1 = nn.AvgPool2d(2,2)\n",
    "      \n",
    "        self.convd2 = nn.Conv2d(32, 64, 1, stride=1, padding=0, dilation=1)      \n",
    "        self.pool2 = nn.AvgPool2d(1,1)\n",
    "\n",
    "        self.convd3 = nn.Conv2d(64, 128, 1, stride=1, padding=0, dilation=1)      \n",
    "\n",
    "        self.convd4 = nn.Conv2d(128, 256, 1, stride=1, padding=0, dilation=1)\n",
    "        self.convd5 = nn.Conv2d(256, 512, 1, stride=1, padding=0, dilation=1)\n",
    "        self.convd7 = nn.Conv2d(512, 1024, 1, stride=1, padding=0, dilation=1)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.init(x) + self.pool1(self.convd1(x))\n",
    "        x2 = self.conv1(x1) + self.pool2(self.convd2(x1))\n",
    "        x3 = self.conv2(x2) + self.pool1(self.convd3(x2))\n",
    "        x4 = self.conv3(x3) + self.pool1(self.convd4(x3))\n",
    "        x5 = self.conv4(x4) + self.pool1(self.convd5(x4))       \n",
    "        x6 = self.conv5(x5) + x5\n",
    "        x7 = self.conv6(x6) + self.pool1(self.convd7(x6)) \n",
    "        x8 = self.conv7(x7) + x7\n",
    "        x9 = self.pool(x8)\n",
    "        x10 = x9.view(x9.size(0), -1)\n",
    "        # x11 = self.fc(x10)\n",
    "        return x11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise, Pointwise convolution + dilation \n",
    "class depth_point2(nn.Module):\n",
    "    def __init__(self, input_size, output_size, padding ,stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(input_size, input_size, 3, stride=stride, padding=padding, dilation=2, groups=input_size),\n",
    "            nn.BatchNorm2d(input_size),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "\n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(input_size, output_size, 1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(output_size),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# MobileNetV1\n",
    "class MobileNetv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.init = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1, dilation=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv1 = depth_point(32, 64)\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            depth_point(64, 128 , stride=2),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            depth_point(128, 256, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.conv4 = depth_point(256, 512, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512),\n",
    "            depth_point(512, 512)\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            depth_point(512, 1024, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            depth_point(1024, 1024, stride=2)\n",
    "        )\n",
    "\n",
    "        self.convd1 = nn.Conv2d(35, 32, 1, stride=1, padding=0, dilation=1)      \n",
    "        self.pool1 = nn.AvgPool2d(2,2)\n",
    "         \n",
    "        self.convd2 = nn.Conv2d(99, 64, 1, stride=1, padding=0, dilation=1)      \n",
    "        self.pool2 = nn.AvgPool2d(4,4)\n",
    "\n",
    "        self.convd3 = nn.Conv2d(163, 128, 1, stride=1, padding=0, dilation=1)      \n",
    "        self.pool3 = nn.AvgPool2d(8,8)\n",
    "\n",
    "        self.convd4 = nn.Conv2d(419, 256, 1, stride=1, padding=0, dilation=1)\n",
    "        self.convd5 = nn.Conv2d(931, 512, 1, stride=1, padding=0, dilation=1)\n",
    "\n",
    "        self.pool4= nn.AvgPool2d(16,16)\n",
    "        self.convd6 = nn.Conv2d(1443, 512, 1, stride=1, padding=0, dilation=1)\n",
    "\n",
    "        self.convd7 = nn.Conv2d(1955, 1024, 1, stride=1, padding=0, dilation=1)\n",
    "        self.pool5= nn.AvgPool2d(32,32)\n",
    "        self.convd8 = nn.Conv2d(2979, 1024, 1, stride=1, padding=0, dilation=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.convd1(torch.cat([self.init(x) , self.pool1(x)], dim=1))\n",
    "        x2 = self.convd2(torch.cat([self.conv1(x1), x1, self.pool1(x)], dim =1))\n",
    "        x3 = self.convd3(torch.cat([self.conv2(x2), self.pool1(x1), self.pool2(x)], dim=1))\n",
    "        x4 = self.convd4(torch.cat([self.conv3(x3), self.pool1(x3), self.pool2(x1), self.pool3(x)], dim=1))\n",
    "        x5 = self.convd5(torch.cat([self.conv4(x4), self.pool1(x4), self.pool2(x3), self.pool3(x1), self.pool4(x)], dim=1))\n",
    "        x6 = self.convd6(torch.cat([self.conv5(x5), x5 , self.pool1(x4), self.pool2(x3), self.pool3(x1), self.pool4(x)], dim=1))\n",
    "        x7 = self.convd7(torch.cat([self.conv6(x6) , self.pool1(x5), self.pool2(x4), self.pool3(x3), self.pool4(x1), self.pool5(x)], dim=1))\n",
    "        x8 = self.convd8(torch.cat([self.conv7(x7), x7 , self.pool1(x5), self.pool2(x4), self.pool3(x3), self.pool4(x1), self.pool5(x) ], dim=1))\n",
    "        x9 = self.pool(x8)\n",
    "        x10 = x9.view(x9.size(0), -1)\n",
    "        # x11 = self.fc(x10)\n",
    "        return x11\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MobileNet에 적용할 ResNext Block의 한 unit \n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_planes,inner_planes, group = 32):\n",
    "        super(BottleNeck, self).__init__()       \n",
    "        ## mobilenet에서 resnext를 적용한 layer 구간: \n",
    "        ## (depthwise + pointwise conv w/ ch = 512)이 5개 연속인 구간\n",
    "        ## group을 32개로 나눠 각 unit은 첫 layer를 제외하고 16개의 ch를 갖는다.\n",
    "        ## 첫 layer에는 input ch이 512로 들어와 모든 unit의 input ch이 512dim이다. \n",
    "        self.dw = nn.Sequential(\n",
    "          depth_point(in_planes, inner_planes, stride=1),\n",
    "          depth_point(inner_planes, inner_planes, stride=1),\n",
    "          depth_point(inner_planes, inner_planes, stride=1),\n",
    "          depth_point(inner_planes, inner_planes, stride=1),\n",
    "          depth_point(inner_planes, inner_planes, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dw(x)\n",
    "        return out\n",
    "\n",
    "#MobileNet에 적용할 ResNext Block (32 groups)\n",
    "class MobileNetBottleNeck(nn.Module):\n",
    "  def __init__(self, in_planes=512, inner_planes=16, out_plane = 256, group = 32):\n",
    "    super(MobileNetBottleNeck,self).__init__()\n",
    "    self.group = group\n",
    "    self.bottleneck_list = [BottleNeck(in_planes,inner_planes, group).to(\"cuda\") for _ in range(self.group)]\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = [self.bottleneck_list[i](x) for i in range(self.group)]   ## 32개의 서로 다른 unit 생성\n",
    "    out = torch.cat(out, dim=1)                                     ## concatenate block units\n",
    "    out += x                                                        ## skipped connection\n",
    "    return out\n",
    "\n",
    "# MobileNetV1\n",
    "class MobileNetv3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv1 = depth_point(32, 64)\n",
    "        # down sample\n",
    "        self.conv2 = nn.Sequential(\n",
    "            depth_point(64, 128 , stride=2),\n",
    "            depth_point(128, 128)\n",
    "        )\n",
    "        # down sample\n",
    "        self.conv3 = nn.Sequential(\n",
    "            depth_point(128, 256, stride=2),\n",
    "            depth_point(256, 256)\n",
    "        )\n",
    "        self.conv4 = depth_point(256, 512, stride=2)\n",
    "\n",
    "        self.conv5 = MobileNetBottleNeck(512, 16, 512, 32)\n",
    "        # down sample\n",
    "        self.conv6 = nn.Sequential(\n",
    "            depth_point(512, 1024, stride=2)\n",
    "        )\n",
    "        # down sample\n",
    "        self.conv7 = nn.Sequential(\n",
    "            depth_point(1024, 1024, stride=2)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_chkp_pth = \"\"\n",
    "model2_chkp_pth = \"\"\n",
    "model3_chkp_pth = \"\"\n",
    "model4_chkp_pth = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MobileNetv2().to(device)\n",
    "model1 = MobileNetv1().to(device)\n",
    "model3 = MobileNetv3().to(device)\n",
    "model4 = MobileNetv4().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ypred(trainloader,model, device):\n",
    "    ypred_list = []\n",
    "    model.eval()\n",
    "    for i, data in enumerate(tqdm(trainloader)):\n",
    "        inputs, _ = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outputs = model(inputs).detach().cpu().item()\n",
    "        ypred_list.append(outputs)\n",
    "\n",
    "    return ypred_list\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble w/ xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypred_model1 = get_ypred(train_dl, model1, device) # bs, 1024\n",
    "ypred_model2 = get_ypred(train_dl, model2, device) # bs, 1024\n",
    "ypred_model3 = get_ypred(train_dl, model3, device) # bs, 1024\n",
    "ypred_model4 = get_ypred(train_dl, model4, device) # bs, 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = xgb.XGBClassifier(objective='binary:logistic')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
