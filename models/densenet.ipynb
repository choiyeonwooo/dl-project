{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"main (2).ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9ab985881e664ba38fb486b843518b83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e8414c61819f41909b2f88b54993f0af","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b34039eb9585454c9cad1c2c75bcb54d","IPY_MODEL_9acc4f795f9c47249a83b7f900eb16c7","IPY_MODEL_1e1b8bc3791248318d8f43e2c25440dc"]}},"e8414c61819f41909b2f88b54993f0af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b34039eb9585454c9cad1c2c75bcb54d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a40030891cc34a6280bab2c1a5fe1fd2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7fa85eda31e74ab6b8615e51b91913d9"}},"9acc4f795f9c47249a83b7f900eb16c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f720dfeb1e1c4d43b53ef6a31cdf31a0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_baa00c2bd1e745b88e798cc6b03f76ed"}},"1e1b8bc3791248318d8f43e2c25440dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d0071a420195414c82d1a903e5e6b017","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:03&lt;00:00, 54327939.54it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2e500e316c549829f3f332b8692dd60"}},"a40030891cc34a6280bab2c1a5fe1fd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7fa85eda31e74ab6b8615e51b91913d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f720dfeb1e1c4d43b53ef6a31cdf31a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"baa00c2bd1e745b88e798cc6b03f76ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0071a420195414c82d1a903e5e6b017":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f2e500e316c549829f3f332b8692dd60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"9ZC_c0PTYMWU"},"source":["## Environment Setting\n","Google drive mount (for Colab users) and package importing.\n","You can optionally install and import torchensemble package for ensemble learning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySwX49PAYMWW","executionInfo":{"status":"ok","timestamp":1640097382600,"user_tz":-540,"elapsed":15730,"user":{"displayName":"김영아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16349982681101407644"}},"outputId":"af508bd0-81f6-42da-f76f-c1556730f404"},"source":["from google.colab import drive\n","drive.mount('mobilenet')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at mobilenet\n"]}]},{"cell_type":"code","source":["# import package\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torchsummary import summary\n","\n","\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import os\n","\n","from torchvision import utils\n","import matplotlib.pyplot as plt\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","import numpy as np\n","import time\n","import copy"],"metadata":{"id":"ur8qWuCnS11Y","executionInfo":{"status":"ok","timestamp":1640097388377,"user_tz":-540,"elapsed":5779,"user":{"displayName":"김영아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16349982681101407644"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# specify path to data\n","transform = transforms.Compose(\n","    [transforms.ToTensor()])\n","\n","train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","train_dl = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n","\n","val_ds = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","val_dl = torch.utils.data.DataLoader(val_ds, batch_size=32, shuffle=False)"],"metadata":{"id":"glK8_CIHS4KT","executionInfo":{"status":"ok","timestamp":1640097396012,"user_tz":-540,"elapsed":7667,"user":{"displayName":"김영아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16349982681101407644"}},"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["9ab985881e664ba38fb486b843518b83","e8414c61819f41909b2f88b54993f0af","b34039eb9585454c9cad1c2c75bcb54d","9acc4f795f9c47249a83b7f900eb16c7","1e1b8bc3791248318d8f43e2c25440dc","a40030891cc34a6280bab2c1a5fe1fd2","7fa85eda31e74ab6b8615e51b91913d9","f720dfeb1e1c4d43b53ef6a31cdf31a0","baa00c2bd1e745b88e798cc6b03f76ed","d0071a420195414c82d1a903e5e6b017","f2e500e316c549829f3f332b8692dd60"]},"outputId":"fe0af7bd-8261-4be8-8fb5-1d315abcf425"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ab985881e664ba38fb486b843518b83","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# Depthwise, Pointwise convolution\n","class depth_point(nn.Module):\n","    def __init__(self, input_size, output_size, stride=1):\n","        super().__init__()\n","\n","        self.depthwise = nn.Sequential(\n","            nn.Conv2d(input_size, input_size, 3, stride=stride, padding=1, groups=input_size),\n","            nn.BatchNorm2d(input_size),\n","            nn.ReLU6(),\n","        )\n","\n","        self.pointwise = nn.Sequential(\n","            nn.Conv2d(input_size, output_size, 1, stride=1, padding=0),\n","            nn.BatchNorm2d(output_size),\n","            nn.ReLU6()\n","        )\n","    \n","    def forward(self, x):\n","        x = self.depthwise(x)\n","        x = self.pointwise(x)\n","        return x\n","\n","# Depthwise, Pointwise convolution + dilation \n","class depth_point2(nn.Module):\n","    def __init__(self, input_size, output_size, padding ,stride=1):\n","        super().__init__()\n","\n","        self.depthwise = nn.Sequential(\n","            nn.Conv2d(input_size, input_size, 3, stride=stride, padding=padding, dilation=2, groups=input_size),\n","            nn.BatchNorm2d(input_size),\n","            nn.ReLU6(),\n","        )\n","\n","        self.pointwise = nn.Sequential(\n","            nn.Conv2d(input_size, output_size, 1, stride=1, padding=0),\n","            nn.BatchNorm2d(output_size),\n","            nn.ReLU6()\n","        )\n","    \n","    def forward(self, x):\n","        x = self.depthwise(x)\n","        x = self.pointwise(x)\n","        return x\n","\n","\n","\n","# MobileNetV1\n","class MobileNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.init = nn.Sequential(\n","            nn.Conv2d(3, 32, 3, stride=2, padding=1, dilation=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU()\n","        )\n","        \n","        self.conv1 = depth_point(32, 64)\n","\n","        self.conv2 = nn.Sequential(\n","            depth_point(64, 128 , stride=2),\n","        )\n","\n","        self.conv3 = nn.Sequential(\n","            depth_point(128, 256, stride=2),\n","        )\n","        \n","        self.conv4 = depth_point(256, 512, stride=2)\n","        \n","        self.conv5 = nn.Sequential(\n","            depth_point(512, 512),\n","            depth_point(512, 512),\n","            depth_point(512, 512),\n","            depth_point(512, 512),\n","            depth_point(512, 512)\n","        )\n","\n","        self.conv6 = nn.Sequential(\n","            depth_point(512, 1024, stride=2)\n","        )\n","\n","        self.conv7 = nn.Sequential(\n","            depth_point(1024, 1024, stride=2)\n","        )\n","\n","        self.convd1 = nn.Conv2d(35, 32, 1, stride=1, padding=0, dilation=1)      \n","        self.pool1 = nn.AvgPool2d(2,2)\n","         \n","        self.convd2 = nn.Conv2d(99, 64, 1, stride=1, padding=0, dilation=1)      \n","        self.pool2 = nn.AvgPool2d(4,4)\n","\n","        self.convd3 = nn.Conv2d(163, 128, 1, stride=1, padding=0, dilation=1)      \n","        self.pool3 = nn.AvgPool2d(8,8)\n","\n","        self.convd4 = nn.Conv2d(419, 256, 1, stride=1, padding=0, dilation=1)\n","        self.convd5 = nn.Conv2d(931, 512, 1, stride=1, padding=0, dilation=1)\n","\n","        self.pool4= nn.AvgPool2d(16,16)\n","        self.convd6 = nn.Conv2d(1443, 512, 1, stride=1, padding=0, dilation=1)\n","\n","        self.convd7 = nn.Conv2d(1955, 1024, 1, stride=1, padding=0, dilation=1)\n","        self.pool5= nn.AvgPool2d(32,32)\n","        self.convd8 = nn.Conv2d(2979, 1024, 1, stride=1, padding=0, dilation=1)\n","        self.pool = nn.AdaptiveAvgPool2d((1,1))\n","        self.fc = nn.Linear(1024, 10)\n","\n","    def forward(self, x):\n","        x1 = self.convd1(torch.cat([self.init(x) , self.pool1(x)], dim=1))\n","        x2 = self.convd2(torch.cat([self.conv1(x1), x1, self.pool1(x)], dim =1))\n","        x3 = self.convd3(torch.cat([self.conv2(x2), self.pool1(x1), self.pool2(x)], dim=1))\n","        x4 = self.convd4(torch.cat([self.conv3(x3), self.pool1(x3), self.pool2(x1), self.pool3(x)], dim=1))\n","        x5 = self.convd5(torch.cat([self.conv4(x4), self.pool1(x4), self.pool2(x3), self.pool3(x1), self.pool4(x)], dim=1))\n","        x6 = self.convd6(torch.cat([self.conv5(x5), x5 , self.pool1(x4), self.pool2(x3), self.pool3(x1), self.pool4(x)], dim=1))\n","        x7 = self.convd7(torch.cat([self.conv6(x6) , self.pool1(x5), self.pool2(x4), self.pool3(x3), self.pool4(x1), self.pool5(x)], dim=1))\n","        x8 = self.convd8(torch.cat([self.conv7(x7), x7 , self.pool1(x5), self.pool2(x4), self.pool3(x3), self.pool4(x1), self.pool5(x) ], dim=1))\n","        x9 = self.pool(x8)\n","        x10 = x9.view(x9.size(0), -1)\n","        x11 = self.fc(x10)\n","        return x11\n","    \n","def mobilenet():\n","    return MobileNet()"],"metadata":{"id":"bKP393vGS8F8","executionInfo":{"status":"ok","timestamp":1640097396013,"user_tz":-540,"elapsed":3,"user":{"displayName":"김영아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16349982681101407644"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","x = torch.randn((32, 3, 32, 32)).to(device)\n","model = mobilenet().to(device)\n","output = model(x)\n","print('output size:', output.size())\n","summary(model, (3, 32, 32), device=device.type)"],"metadata":{"id":"a-aH90_CS-7N","executionInfo":{"status":"ok","timestamp":1640097405730,"user_tz":-540,"elapsed":9720,"user":{"displayName":"김영아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16349982681101407644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"62546fa5-e0fe-4afc-8c57-90e9a4f7248d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["output size: torch.Size([32, 10])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 16, 16]             896\n","       BatchNorm2d-2           [-1, 32, 16, 16]              64\n","              ReLU-3           [-1, 32, 16, 16]               0\n","         AvgPool2d-4            [-1, 3, 16, 16]               0\n","            Conv2d-5           [-1, 32, 16, 16]           1,152\n","            Conv2d-6           [-1, 32, 16, 16]             320\n","       BatchNorm2d-7           [-1, 32, 16, 16]              64\n","             ReLU6-8           [-1, 32, 16, 16]               0\n","            Conv2d-9           [-1, 64, 16, 16]           2,112\n","      BatchNorm2d-10           [-1, 64, 16, 16]             128\n","            ReLU6-11           [-1, 64, 16, 16]               0\n","      depth_point-12           [-1, 64, 16, 16]               0\n","        AvgPool2d-13            [-1, 3, 16, 16]               0\n","           Conv2d-14           [-1, 64, 16, 16]           6,400\n","           Conv2d-15             [-1, 64, 8, 8]             640\n","      BatchNorm2d-16             [-1, 64, 8, 8]             128\n","            ReLU6-17             [-1, 64, 8, 8]               0\n","           Conv2d-18            [-1, 128, 8, 8]           8,320\n","      BatchNorm2d-19            [-1, 128, 8, 8]             256\n","            ReLU6-20            [-1, 128, 8, 8]               0\n","      depth_point-21            [-1, 128, 8, 8]               0\n","        AvgPool2d-22             [-1, 32, 8, 8]               0\n","        AvgPool2d-23              [-1, 3, 8, 8]               0\n","           Conv2d-24            [-1, 128, 8, 8]          20,992\n","           Conv2d-25            [-1, 128, 4, 4]           1,280\n","      BatchNorm2d-26            [-1, 128, 4, 4]             256\n","            ReLU6-27            [-1, 128, 4, 4]               0\n","           Conv2d-28            [-1, 256, 4, 4]          33,024\n","      BatchNorm2d-29            [-1, 256, 4, 4]             512\n","            ReLU6-30            [-1, 256, 4, 4]               0\n","      depth_point-31            [-1, 256, 4, 4]               0\n","        AvgPool2d-32            [-1, 128, 4, 4]               0\n","        AvgPool2d-33             [-1, 32, 4, 4]               0\n","        AvgPool2d-34              [-1, 3, 4, 4]               0\n","           Conv2d-35            [-1, 256, 4, 4]         107,520\n","           Conv2d-36            [-1, 256, 2, 2]           2,560\n","      BatchNorm2d-37            [-1, 256, 2, 2]             512\n","            ReLU6-38            [-1, 256, 2, 2]               0\n","           Conv2d-39            [-1, 512, 2, 2]         131,584\n","      BatchNorm2d-40            [-1, 512, 2, 2]           1,024\n","            ReLU6-41            [-1, 512, 2, 2]               0\n","      depth_point-42            [-1, 512, 2, 2]               0\n","        AvgPool2d-43            [-1, 256, 2, 2]               0\n","        AvgPool2d-44            [-1, 128, 2, 2]               0\n","        AvgPool2d-45             [-1, 32, 2, 2]               0\n","        AvgPool2d-46              [-1, 3, 2, 2]               0\n","           Conv2d-47            [-1, 512, 2, 2]         477,184\n","           Conv2d-48            [-1, 512, 2, 2]           5,120\n","      BatchNorm2d-49            [-1, 512, 2, 2]           1,024\n","            ReLU6-50            [-1, 512, 2, 2]               0\n","           Conv2d-51            [-1, 512, 2, 2]         262,656\n","      BatchNorm2d-52            [-1, 512, 2, 2]           1,024\n","            ReLU6-53            [-1, 512, 2, 2]               0\n","      depth_point-54            [-1, 512, 2, 2]               0\n","           Conv2d-55            [-1, 512, 2, 2]           5,120\n","      BatchNorm2d-56            [-1, 512, 2, 2]           1,024\n","            ReLU6-57            [-1, 512, 2, 2]               0\n","           Conv2d-58            [-1, 512, 2, 2]         262,656\n","      BatchNorm2d-59            [-1, 512, 2, 2]           1,024\n","            ReLU6-60            [-1, 512, 2, 2]               0\n","      depth_point-61            [-1, 512, 2, 2]               0\n","           Conv2d-62            [-1, 512, 2, 2]           5,120\n","      BatchNorm2d-63            [-1, 512, 2, 2]           1,024\n","            ReLU6-64            [-1, 512, 2, 2]               0\n","           Conv2d-65            [-1, 512, 2, 2]         262,656\n","      BatchNorm2d-66            [-1, 512, 2, 2]           1,024\n","            ReLU6-67            [-1, 512, 2, 2]               0\n","      depth_point-68            [-1, 512, 2, 2]               0\n","           Conv2d-69            [-1, 512, 2, 2]           5,120\n","      BatchNorm2d-70            [-1, 512, 2, 2]           1,024\n","            ReLU6-71            [-1, 512, 2, 2]               0\n","           Conv2d-72            [-1, 512, 2, 2]         262,656\n","      BatchNorm2d-73            [-1, 512, 2, 2]           1,024\n","            ReLU6-74            [-1, 512, 2, 2]               0\n","      depth_point-75            [-1, 512, 2, 2]               0\n","           Conv2d-76            [-1, 512, 2, 2]           5,120\n","      BatchNorm2d-77            [-1, 512, 2, 2]           1,024\n","            ReLU6-78            [-1, 512, 2, 2]               0\n","           Conv2d-79            [-1, 512, 2, 2]         262,656\n","      BatchNorm2d-80            [-1, 512, 2, 2]           1,024\n","            ReLU6-81            [-1, 512, 2, 2]               0\n","      depth_point-82            [-1, 512, 2, 2]               0\n","        AvgPool2d-83            [-1, 256, 2, 2]               0\n","        AvgPool2d-84            [-1, 128, 2, 2]               0\n","        AvgPool2d-85             [-1, 32, 2, 2]               0\n","        AvgPool2d-86              [-1, 3, 2, 2]               0\n","           Conv2d-87            [-1, 512, 2, 2]         739,328\n","           Conv2d-88            [-1, 512, 1, 1]           5,120\n","      BatchNorm2d-89            [-1, 512, 1, 1]           1,024\n","            ReLU6-90            [-1, 512, 1, 1]               0\n","           Conv2d-91           [-1, 1024, 1, 1]         525,312\n","      BatchNorm2d-92           [-1, 1024, 1, 1]           2,048\n","            ReLU6-93           [-1, 1024, 1, 1]               0\n","      depth_point-94           [-1, 1024, 1, 1]               0\n","        AvgPool2d-95            [-1, 512, 1, 1]               0\n","        AvgPool2d-96            [-1, 256, 1, 1]               0\n","        AvgPool2d-97            [-1, 128, 1, 1]               0\n","        AvgPool2d-98             [-1, 32, 1, 1]               0\n","        AvgPool2d-99              [-1, 3, 1, 1]               0\n","          Conv2d-100           [-1, 1024, 1, 1]       2,002,944\n","          Conv2d-101           [-1, 1024, 1, 1]          10,240\n","     BatchNorm2d-102           [-1, 1024, 1, 1]           2,048\n","           ReLU6-103           [-1, 1024, 1, 1]               0\n","          Conv2d-104           [-1, 1024, 1, 1]       1,049,600\n","     BatchNorm2d-105           [-1, 1024, 1, 1]           2,048\n","           ReLU6-106           [-1, 1024, 1, 1]               0\n","     depth_point-107           [-1, 1024, 1, 1]               0\n","       AvgPool2d-108            [-1, 512, 1, 1]               0\n","       AvgPool2d-109            [-1, 256, 1, 1]               0\n","       AvgPool2d-110            [-1, 128, 1, 1]               0\n","       AvgPool2d-111             [-1, 32, 1, 1]               0\n","       AvgPool2d-112              [-1, 3, 1, 1]               0\n","          Conv2d-113           [-1, 1024, 1, 1]       3,051,520\n","AdaptiveAvgPool2d-114           [-1, 1024, 1, 1]               0\n","          Linear-115                   [-1, 10]          10,250\n","================================================================\n","Total params: 9,547,530\n","Trainable params: 9,547,530\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 2.55\n","Params size (MB): 36.42\n","Estimated Total Size (MB): 38.98\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# define loss function, optimizer, lr_scheduler\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","model = MobileNet().to(device)\n","loss_func = nn.CrossEntropyLoss(reduction='sum')\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","# Function to train the network\n","\n","def train_val(net, params_train): #, model_path='./cifar_net.pth'\n","    max_epoch=params_train['max_epoch']\n","    trainloader=params_train['train_dl']\n","    testloader=params_train['val_dl']\n","    crit=params_train['loss_func']\n","    opt=params_train['optimizer']\n","    path2weights = params_train['path2weights']\n","    history = []\n","    best_model_wts = copy.deepcopy(net.state_dict())\n","    start_time = time.time()\n","    best_loss = float('inf')\n","    \n","    for epoch in range(max_epoch):  # loop over the dataset multiple times\n","\n","        print('Epoch {}/{}'.format(epoch+1, max_epoch))\n","        running_loss = 0.0\n","        net.train()\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels      \n","            inputs, labels = data\n","\n","            # Training on GPU\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            # zero the parameter gradients\n","            opt.zero_grad()\n","\n","            outputs = net(inputs)\n","\n","            loss = crit(outputs, labels)\n","            loss.backward()\n","            opt.step()\n"," \n","            running_loss += loss.item()\n","        train_loss = running_loss / 50000\n","\n","        net.eval()\n","        with torch.no_grad():\n","            running_loss_1 = 0.0\n","            running_metric_1 = 0.0\n","            for j, data_1 in enumerate(testloader, 0):\n","                    # get the inputs; data is a list of [inputs, labels]\n","\n","                    inputs_1, labels_1 = data_1\n","                    inputs_1 = inputs_1.to(device)\n","                    labels_1 = labels_1.to(device)\n","     \n","                    # forward\n","                    outputs_1 = net(inputs_1)\n","                    loss1 = crit(outputs_1, labels_1)\n","                    \n","\n","                    pred1 = outputs_1.argmax(1, keepdim=True)\n","                    metrics = pred1.eq(labels_1.view_as(pred1)).sum().item()\n","                    if metrics is not None:\n","                       running_metric_1 += metrics\n","                    # print statistics\n","                    running_loss_1 += loss1.item()                      \n","            metrix = running_metric_1 / 10000\n","            val_loss = running_loss_1 / 10000\n","            \n","            \n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model_wts = copy.deepcopy(net.state_dict())\n","            torch.save(net.state_dict(), path2weights)\n","            print('Copied best model weights!')\n","\n","        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*metrix, (time.time()-start_time)/60))\n","        history.append(metrix)\n","        print('-'*10)\n","        \n","\n","    net.load_state_dict(best_model_wts)           \n","    #torch.save(net.state_dict(), model_path)\n","    print('Finished Training')\n","    print('Saved Trained Model')\n","    return history  "],"metadata":{"id":"u0GelRdYTBi0","executionInfo":{"status":"ok","timestamp":1640097406092,"user_tz":-540,"elapsed":391,"user":{"displayName":"김영아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16349982681101407644"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2badf758-6608-4059-c797-99e1dbb046bc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["# define the training parameters\n","params_train = {\n","    'max_epoch':30,\n","    'optimizer':optimizer,\n","    'loss_func':loss_func,\n","    'train_dl':train_dl,\n","    'val_dl':val_dl,\n","    'path2weights':'./models/weights.pt',\n","}\n","\n","# check the directory to save weights.pt\n","def createFolder(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSerror:\n","        print('Error')\n","\n","        \n","createFolder('./models')"],"metadata":{"id":"0zPVPO63TDpw","executionInfo":{"status":"ok","timestamp":1640097406092,"user_tz":-540,"elapsed":4,"user":{"displayName":"김영아","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16349982681101407644"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["history =  train_val(model, params_train)"],"metadata":{"id":"qtIP6KqnTErf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce8f2270-70d2-4fdf-fc38-d8d756d192c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","Copied best model weights!\n","train loss: 1.591636, val loss: 1.289117, accuracy: 54.72, time: 1.8830 min\n","----------\n","Epoch 2/30\n","Copied best model weights!\n","train loss: 1.213942, val loss: 1.072827, accuracy: 61.76, time: 3.7480 min\n","----------\n","Epoch 3/30\n","Copied best model weights!\n","train loss: 1.053839, val loss: 1.012387, accuracy: 64.54, time: 5.6144 min\n","----------\n","Epoch 4/30\n","Copied best model weights!\n","train loss: 0.944169, val loss: 0.969837, accuracy: 66.58, time: 7.4770 min\n","----------\n","Epoch 5/30\n","Copied best model weights!\n","train loss: 0.845161, val loss: 0.880040, accuracy: 70.66, time: 9.3510 min\n","----------\n","Epoch 6/30\n","train loss: 0.792843, val loss: 0.925369, accuracy: 68.89, time: 11.2169 min\n","----------\n","Epoch 7/30\n","Copied best model weights!\n","train loss: 0.762778, val loss: 0.870954, accuracy: 70.83, time: 13.0773 min\n","----------\n","Epoch 8/30\n","Copied best model weights!\n","train loss: 0.678238, val loss: 0.855586, accuracy: 71.64, time: 14.9507 min\n","----------\n","Epoch 9/30\n","Copied best model weights!\n","train loss: 0.614532, val loss: 0.782080, accuracy: 74.03, time: 16.8178 min\n","----------\n","Epoch 10/30\n","train loss: 0.649613, val loss: 1.002593, accuracy: 69.64, time: 18.6827 min\n","----------\n","Epoch 11/30\n","Copied best model weights!\n","train loss: 0.617092, val loss: 0.771102, accuracy: 75.91, time: 20.5587 min\n","----------\n","Epoch 12/30\n","train loss: 0.525832, val loss: 0.915119, accuracy: 71.59, time: 22.4253 min\n","----------\n","Epoch 13/30\n","train loss: 0.513983, val loss: 1.106467, accuracy: 67.66, time: 24.2891 min\n","----------\n","Epoch 14/30\n","train loss: 0.508439, val loss: 0.813233, accuracy: 75.18, time: 26.1611 min\n","----------\n","Epoch 15/30\n","train loss: 0.446449, val loss: 0.938935, accuracy: 72.64, time: 28.0321 min\n","----------\n","Epoch 16/30\n","train loss: 0.437717, val loss: 1.030208, accuracy: 71.64, time: 29.9046 min\n","----------\n","Epoch 17/30\n","train loss: 0.416095, val loss: 0.905072, accuracy: 74.67, time: 31.7708 min\n","----------\n","Epoch 18/30\n","train loss: 0.445575, val loss: 0.843975, accuracy: 75.96, time: 33.6420 min\n","----------\n","Epoch 19/30\n","train loss: 0.343822, val loss: 0.899555, accuracy: 75.64, time: 35.5089 min\n","----------\n","Epoch 20/30\n","train loss: 0.384062, val loss: 0.874584, accuracy: 76.32, time: 37.3774 min\n","----------\n","Epoch 21/30\n","train loss: 0.325845, val loss: 1.016549, accuracy: 75.26, time: 39.2428 min\n","----------\n","Epoch 22/30\n","train loss: 0.406259, val loss: 0.936849, accuracy: 75.50, time: 41.1203 min\n","----------\n","Epoch 23/30\n","train loss: 0.336838, val loss: 1.029692, accuracy: 75.42, time: 42.9835 min\n","----------\n","Epoch 24/30\n","train loss: 0.367187, val loss: 1.179177, accuracy: 73.56, time: 44.8536 min\n","----------\n","Epoch 25/30\n","train loss: 0.351156, val loss: 1.038866, accuracy: 75.63, time: 46.7102 min\n","----------\n","Epoch 26/30\n","train loss: 0.325879, val loss: 0.983312, accuracy: 76.34, time: 48.5621 min\n","----------\n","Epoch 27/30\n","train loss: 0.316230, val loss: 1.056552, accuracy: 75.24, time: 50.4115 min\n","----------\n","Epoch 28/30\n","train loss: 0.377289, val loss: 0.928793, accuracy: 76.12, time: 52.2664 min\n","----------\n","Epoch 29/30\n","train loss: 0.280131, val loss: 1.922363, accuracy: 63.92, time: 54.1129 min\n","----------\n","Epoch 30/30\n"]}]},{"cell_type":"code","source":["# train-val progress\n","num_epochs = params_train['max_epoch']\n","# plot accuracy progress\n","plt.title('Train-Val Accuracy')\n","plt.plot(range(1, num_epochs+1), history, label='val')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Training Epochs')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"Hl0RkbV6TGGf"},"execution_count":null,"outputs":[]}]}